{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c43add60463d448b997bd979ab7b889f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ae5452d0ac44279907858eddc3e4864",
              "IPY_MODEL_7ab1955e6c5d425abd270b509c7a7c1f",
              "IPY_MODEL_3d9f118330d644139f9f0961ca17d5ed"
            ],
            "layout": "IPY_MODEL_f49fd54c2bc34793bde09a14c769e794"
          }
        },
        "6ae5452d0ac44279907858eddc3e4864": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_192262c039f64a4db3eb863ccb3f1abf",
            "placeholder": "​",
            "style": "IPY_MODEL_819bf6b5b9d341b4ba65fdd62a508b93",
            "value": "model.safetensors: 100%"
          }
        },
        "7ab1955e6c5d425abd270b509c7a7c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f77b4f69df864515af3fc98393651293",
            "max": 173153470,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_416e965ca0874c2baa04423c2fcaf5e1",
            "value": 173153470
          }
        },
        "3d9f118330d644139f9f0961ca17d5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b8dcbe8bf7e4f74b6044143737c6d69",
            "placeholder": "​",
            "style": "IPY_MODEL_6bac9cb219b94f19a33ec9c34c0b4d01",
            "value": " 173M/173M [00:02&lt;00:00, 163MB/s]"
          }
        },
        "f49fd54c2bc34793bde09a14c769e794": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "192262c039f64a4db3eb863ccb3f1abf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "819bf6b5b9d341b4ba65fdd62a508b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f77b4f69df864515af3fc98393651293": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "416e965ca0874c2baa04423c2fcaf5e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b8dcbe8bf7e4f74b6044143737c6d69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bac9cb219b94f19a33ec9c34c0b4d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11AifX8x7e1x",
        "outputId": "392a9978-d34b-4ed7-83df-f5e06cb06e61"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install timm torchvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1YLiSEus37v",
        "outputId": "f077da52-884f-4f8c-8fcf-211839fe9721"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.22)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from timm) (2.9.0+cu126)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.36.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->timm) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->timm) (3.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (25.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->timm) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2025.11.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdvQXRz54XjT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "3122f1ae-66bc-45d9-e363-2e17e5af3a19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Classes: ['Blight', 'Healthy', 'Spot']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "No pretrained weights exist for efficientnet_b6. Use `pretrained=False` for random init.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1132325380.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;31m# Model (From Scratch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;31m# =========================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m backbone = timm.create_model(\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0mMODEL_NAME\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(model_name, pretrained, pretrained_cfg, pretrained_cfg_overlay, checkpoint_path, cache_dir, scriptable, exportable, no_jit, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mcreate_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_entrypoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mset_layer_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscriptable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscriptable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexportable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexportable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_jit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mno_jit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         model = create_fn(\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mpretrained_cfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained_cfg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/timm/models/efficientnet.py\u001b[0m in \u001b[0;36mefficientnet_b6\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m   2128\u001b[0m     \u001b[0;34m\"\"\" EfficientNet-B6 \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2129\u001b[0m     \u001b[0;31m# NOTE for train, drop_rate should be 0.5, drop_path_rate should be 0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2130\u001b[0;31m     model = _gen_efficientnet(\n\u001b[0m\u001b[1;32m   2131\u001b[0m         'efficientnet_b6', channel_multiplier=1.8, depth_multiplier=2.6, pretrained=pretrained, **kwargs)\n\u001b[1;32m   2132\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/timm/models/efficientnet.py\u001b[0m in \u001b[0;36m_gen_efficientnet\u001b[0;34m(variant, channel_multiplier, depth_multiplier, channel_divisor, group_size, pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     )\n\u001b[0;32m--> 762\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_effnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/timm/models/efficientnet.py\u001b[0m in \u001b[0;36m_create_effnet\u001b[0;34m(variant, pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0mpretrained_strict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pretrained_strict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m     model = build_model_with_cfg(\n\u001b[0m\u001b[1;32m    464\u001b[0m         \u001b[0mmodel_cls\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mvariant\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/timm/models/_builder.py\u001b[0m in \u001b[0;36mbuild_model_with_cfg\u001b[0;34m(model_cls, variant, pretrained, pretrained_cfg, pretrained_cfg_overlay, model_cfg, feature_cfg, pretrained_strict, pretrained_filter_fn, cache_dir, kwargs_filter, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0mnum_classes_pretrained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'num_classes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'num_classes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         load_pretrained(\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m             \u001b[0mpretrained_cfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained_cfg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/timm/models/_builder.py\u001b[0m in \u001b[0;36mload_pretrained\u001b[0;34m(model, pretrained_cfg, num_classes, in_chans, filter_fn, strict, cache_dir)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'architecture'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'this model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No pretrained weights exist for {model_name}. Use `pretrained=False` for random init.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilter_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No pretrained weights exist for efficientnet_b6. Use `pretrained=False` for random init."
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "# =========================\n",
        "import os, copy\n",
        "import torch, timm\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    f1_score,\n",
        "    recall_score,\n",
        "    precision_score\n",
        ")\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# =========================\n",
        "# Device\n",
        "# =========================\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# =========================\n",
        "# Paths\n",
        "# =========================\n",
        "DATA_DIR = \"/content/drive/MyDrive/corn/my Collected Dataset/528-528\"\n",
        "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
        "VALID_DIR = os.path.join(DATA_DIR, \"valid\")\n",
        "TEST_DIR  = os.path.join(DATA_DIR, \"test\")\n",
        "\n",
        "# =========================\n",
        "# Model Selection\n",
        "# Choose: efficientnet_b5 | efficientnet_b6 | efficientnet_b7\n",
        "# =========================\n",
        "MODEL_NAME = \"efficientnet_b6\"\n",
        "\n",
        "IMG_SIZES = {\n",
        "    \"efficientnet_b5\": 456,\n",
        "    \"efficientnet_b6\": 528,\n",
        "    \"efficientnet_b7\": 600\n",
        "}\n",
        "\n",
        "IMG_SIZE = IMG_SIZES[MODEL_NAME]\n",
        "\n",
        "# =========================\n",
        "# Hyperparameters\n",
        "# =========================\n",
        "BATCH = 4          # reduce if OOM\n",
        "ACCUM_STEPS = 2\n",
        "NUM_EPOCHS = 20\n",
        "PATIENCE = 7\n",
        "LR = 1e-4\n",
        "WEIGHT_DECAY = 1e-5\n",
        "\n",
        "MODEL_SAVE = f\"/content/best_{MODEL_NAME}_from_scratch.pth\"\n",
        "\n",
        "# =========================\n",
        "# Albumentations Transforms\n",
        "# =========================\n",
        "train_tfms = A.Compose([\n",
        "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Rotate(limit=20, p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.Normalize(\n",
        "        mean=(0.485, 0.456, 0.406),\n",
        "        std=(0.229, 0.224, 0.225)\n",
        "    ),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "val_tfms = A.Compose([\n",
        "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
        "    A.Normalize(\n",
        "        mean=(0.485, 0.456, 0.406),\n",
        "        std=(0.229, 0.224, 0.225)\n",
        "    ),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# =========================\n",
        "# Albumentations Dataset Wrapper\n",
        "# =========================\n",
        "class AlbDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.dataset = datasets.ImageFolder(root=root)\n",
        "        self.transform = transform\n",
        "        self.classes = self.dataset.classes\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.dataset.samples[idx]\n",
        "        img = np.array(Image.open(img_path).convert(\"RGB\"))\n",
        "        if self.transform:\n",
        "            img = self.transform(image=img)[\"image\"]\n",
        "        return img, label\n",
        "\n",
        "# =========================\n",
        "# DataLoaders\n",
        "# =========================\n",
        "train_loader = DataLoader(\n",
        "    AlbDataset(TRAIN_DIR, train_tfms),\n",
        "    batch_size=BATCH,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    AlbDataset(VALID_DIR, val_tfms),\n",
        "    batch_size=BATCH,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    AlbDataset(TEST_DIR, val_tfms),\n",
        "    batch_size=BATCH,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "num_classes = len(train_loader.dataset.classes)\n",
        "print(\"Classes:\", train_loader.dataset.classes)\n",
        "\n",
        "# =========================\n",
        "# Model (From Scratch)\n",
        "# =========================\n",
        "backbone = timm.create_model(\n",
        "    MODEL_NAME,\n",
        "    pretrained=True,\n",
        "    num_classes=0,\n",
        "    global_pool=\"\"\n",
        ")\n",
        "\n",
        "class EfficientNetClassifier(nn.Module):\n",
        "    def __init__(self, backbone, num_classes):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(backbone.num_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone.forward_features(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        return self.fc(x)\n",
        "\n",
        "model = EfficientNetClassifier(backbone, num_classes).to(device)\n",
        "\n",
        "# =========================\n",
        "# Loss & Optimizer\n",
        "# =========================\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=LR,\n",
        "    weight_decay=WEIGHT_DECAY\n",
        ")\n",
        "\n",
        "# =========================\n",
        "# Training Loop\n",
        "# =========================\n",
        "best_val_acc = 0.0\n",
        "train_acc_hist, val_acc_hist = [], []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    correct, total = 0, 0\n",
        "\n",
        "    for imgs, labels in train_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(imgs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        preds = outputs.argmax(1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_acc = correct / total\n",
        "    train_acc_hist.append(train_acc)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_correct, val_total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            outputs = model(imgs)\n",
        "            preds = outputs.argmax(1)\n",
        "            val_correct += (preds == labels).sum().item()\n",
        "            val_total += labels.size(0)\n",
        "\n",
        "    val_acc = val_correct / val_total\n",
        "    val_acc_hist.append(val_acc)\n",
        "\n",
        "    print(f\"[Epoch {epoch+1}/{NUM_EPOCHS}] \"\n",
        "          f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), MODEL_SAVE)\n",
        "        print(\"✅ Best model saved\")\n",
        "\n",
        "print(\"Training Finished | Best Val Acc:\", best_val_acc)\n",
        "\n",
        "# =========================\n",
        "# Load Best Model\n",
        "# =========================\n",
        "model.load_state_dict(torch.load(MODEL_SAVE))\n",
        "model.eval()\n",
        "\n",
        "# =========================\n",
        "# Testing & Metrics\n",
        "# =========================\n",
        "all_labels, all_preds = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        outputs = model(imgs)\n",
        "        preds = outputs.argmax(1)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(\n",
        "    all_labels,\n",
        "    all_preds,\n",
        "    target_names=train_loader.dataset.classes\n",
        "))\n",
        "\n",
        "f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
        "recall = recall_score(all_labels, all_preds, average=\"macro\")\n",
        "precision = precision_score(all_labels, all_preds, average=\"macro\")\n",
        "\n",
        "print(f\"F1: {f1:.4f} | Recall: {recall:.4f} | Precision: {precision:.4f}\")\n",
        "\n",
        "# =========================\n",
        "# Confusion Matrix\n",
        "# =========================\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Greens\",\n",
        "    xticklabels=train_loader.dataset.classes,\n",
        "    yticklabels=train_loader.dataset.classes\n",
        ")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# =========================\n",
        "# Accuracy Curves\n",
        "# =========================\n",
        "plt.plot(train_acc_hist, label=\"Train Accuracy\")\n",
        "plt.plot(val_acc_hist, label=\"Validation Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"EfficientNet Training From Scratch\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# =========================\n",
        "# Save to Google Drive\n",
        "# =========================\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# creating the folder in drive with name of : models\n",
        "!mkdir -p /content/drive/MyDrive/Corn_efficientnet_B6_models\n",
        "\n",
        "# copying the model file to the drive folder with the mentioned name: models\n",
        "!cp /content/full_model.pth /content/drive/MyDrive/Corn_efficientnet_B6_models/\n",
        "\n",
        "\n",
        "save_folder = \"/content/drive/MyDrive/Corn_efficientnet_B6_models\"\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "\n",
        "torch.save(model, f\"{save_folder}/{efficientnet_B6}_full_model.pth\")\n",
        "torch.save(model.state_dict(), f\"{save_folder}/{efficientnet_B6}_weights_only.pth\")\n",
        "\n",
        "print(\"✅ ماډل په Google Drive کې ذخیره شو\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Complated EfficientNet-b6 new improved Notebook***"
      ],
      "metadata": {
        "id": "GUcxQ5kUPtHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================================\n",
        "# EfficientNet-B6 Training (ImageNet Pretrained)\n",
        "# Batch=4 | ACCUM_STEPS=2 | AMP Enabled\n",
        "# ======================================================\n",
        "\n",
        "# ----------------------\n",
        "# Imports\n",
        "# ----------------------\n",
        "import os\n",
        "import torch, timm\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, recall_score, precision_score\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "\n",
        "# ----------------------\n",
        "# Device\n",
        "# ----------------------\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# ----------------------\n",
        "# Paths\n",
        "# ----------------------\n",
        "DATA_DIR = \"/content/drive/MyDrive/corn/my Collected Dataset/528-528\"\n",
        "TRAIN_DIR = os.path.join(DATA_DIR, \"train\")\n",
        "VALID_DIR = os.path.join(DATA_DIR, \"valid\")\n",
        "TEST_DIR  = os.path.join(DATA_DIR, \"test\")\n",
        "\n",
        "# ----------------------\n",
        "# Model Config\n",
        "# ----------------------\n",
        "\n",
        "MODEL_NAME = \"tf_efficientnet_b6_ns\"\n",
        "\n",
        "IMG_SIZE = 528\n",
        "\n",
        "# ----------------------\n",
        "# Hyperparameters\n",
        "# ----------------------\n",
        "BATCH = 4\n",
        "ACCUM_STEPS = 2              # effective batch = 8\n",
        "NUM_EPOCHS = 20\n",
        "LR = 5e-5                    # safe for B6\n",
        "WEIGHT_DECAY = 1e-5\n",
        "\n",
        "MODEL_SAVE = f\"/content/best_{MODEL_NAME}_imagenet_pretrained.pth\"\n",
        "\n",
        "# ----------------------\n",
        "# Albumentations\n",
        "# ----------------------\n",
        "train_tfms = A.Compose([\n",
        "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.Rotate(limit=20, p=0.5),\n",
        "    A.RandomBrightnessContrast(p=0.5),\n",
        "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "val_tfms = A.Compose([\n",
        "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
        "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "    ToTensorV2()\n",
        "])\n",
        "\n",
        "# ----------------------\n",
        "# Dataset Wrapper\n",
        "# ----------------------\n",
        "class AlbDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transform=None):\n",
        "        self.dataset = datasets.ImageFolder(root)\n",
        "        self.transform = transform\n",
        "        self.classes = self.dataset.classes\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.dataset.samples[idx]\n",
        "        img = np.array(Image.open(path).convert(\"RGB\"))\n",
        "        if self.transform:\n",
        "            img = self.transform(image=img)[\"image\"]\n",
        "        return img, label\n",
        "\n",
        "# ----------------------\n",
        "# DataLoaders\n",
        "# ----------------------\n",
        "train_loader = DataLoader(AlbDataset(TRAIN_DIR, train_tfms), batch_size=BATCH, shuffle=True, num_workers=2)\n",
        "val_loader   = DataLoader(AlbDataset(VALID_DIR, val_tfms),   batch_size=BATCH, shuffle=False, num_workers=2)\n",
        "test_loader  = DataLoader(AlbDataset(TEST_DIR,  val_tfms),   batch_size=BATCH, shuffle=False, num_workers=2)\n",
        "\n",
        "num_classes = len(train_loader.dataset.classes)\n",
        "print(\"Classes:\", train_loader.dataset.classes)\n",
        "\n",
        "# ----------------------\n",
        "# Model\n",
        "# ----------------------\n",
        "backbone = timm.create_model(\n",
        "    MODEL_NAME,\n",
        "    pretrained=True,\n",
        "    num_classes=0,\n",
        "    global_pool=\"\"\n",
        ")\n",
        "\n",
        "class EfficientNetClassifier(nn.Module):\n",
        "    def __init__(self, backbone, num_classes):\n",
        "        super().__init__()\n",
        "        self.backbone = backbone\n",
        "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(backbone.num_features, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone.forward_features(x)\n",
        "        x = self.pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        return self.fc(x)\n",
        "\n",
        "model = EfficientNetClassifier(backbone, num_classes).to(device)\n",
        "\n",
        "# ----------------------\n",
        "# Loss & Optimizer\n",
        "# ----------------------\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "scaler = GradScaler()\n",
        "\n",
        "# ----------------------\n",
        "# Training\n",
        "# ----------------------\n",
        "best_val_acc = 0.0\n",
        "train_acc_hist, val_acc_hist = [], []\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    correct, total = 0, 0\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    for step, (imgs, labels) in enumerate(train_loader):\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "        with autocast():\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels) / ACCUM_STEPS\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "        if (step + 1) % ACCUM_STEPS == 0:\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        preds = outputs.argmax(1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_acc = correct / total\n",
        "    train_acc_hist.append(train_acc)\n",
        "\n",
        "    model.eval()\n",
        "    val_correct, val_total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            preds = model(imgs).argmax(1)\n",
        "            val_correct += (preds == labels).sum().item()\n",
        "            val_total += labels.size(0)\n",
        "\n",
        "    val_acc = val_correct / val_total\n",
        "    val_acc_hist.append(val_acc)\n",
        "\n",
        "    print(f\"[Epoch {epoch+1}/{NUM_EPOCHS}] Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), MODEL_SAVE)\n",
        "        print(\"✅ Best model saved\")\n",
        "\n",
        "# ----------------------\n",
        "# Testing\n",
        "# ----------------------\n",
        "model.load_state_dict(torch.load(MODEL_SAVE))\n",
        "model.eval()\n",
        "\n",
        "all_labels, all_preds = [], []\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        preds = model(imgs).argmax(1)\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(all_labels, all_preds, target_names=train_loader.dataset.classes))\n",
        "\n",
        "print(\"F1:\", f1_score(all_labels, all_preds, average=\"macro\"))\n",
        "print(\"Recall:\", recall_score(all_labels, all_preds, average=\"macro\"))\n",
        "print(\"Precision:\", precision_score(all_labels, all_preds, average=\"macro\"))\n",
        "\n",
        "# ----------------------\n",
        "# Confusion Matrix\n",
        "# ----------------------\n",
        "cm = confusion_matrix(all_labels, all_preds)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\",\n",
        "            xticklabels=train_loader.dataset.classes,\n",
        "            yticklabels=train_loader.dataset.classes)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"EfficientNet-B6 Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "# ----------------------\n",
        "# Save to Google Drive\n",
        "# ----------------------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "save_folder = \"/content/drive/MyDrive/Corn_efficientnet_B6_models\"\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "\n",
        "torch.save(model, f\"{save_folder}/{MODEL_NAME}_full_model.pth\")\n",
        "torch.save(model.state_dict(), f\"{save_folder}/{MODEL_NAME}_weights_only.pth\")\n",
        "\n",
        "print(\"✅ Model saved to Google Drive\")\n"
      ],
      "metadata": {
        "id": "7mC3Q-eQPOX7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c43add60463d448b997bd979ab7b889f",
            "6ae5452d0ac44279907858eddc3e4864",
            "7ab1955e6c5d425abd270b509c7a7c1f",
            "3d9f118330d644139f9f0961ca17d5ed",
            "f49fd54c2bc34793bde09a14c769e794",
            "192262c039f64a4db3eb863ccb3f1abf",
            "819bf6b5b9d341b4ba65fdd62a508b93",
            "f77b4f69df864515af3fc98393651293",
            "416e965ca0874c2baa04423c2fcaf5e1",
            "4b8dcbe8bf7e4f74b6044143737c6d69",
            "6bac9cb219b94f19a33ec9c34c0b4d01"
          ]
        },
        "outputId": "20934b38-76d2-41f2-ede8-06112269815f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Classes: ['Blight', 'Healthy', 'Spot']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/_factory.py:138: UserWarning: Mapping deprecated model name tf_efficientnet_b6_ns to current tf_efficientnet_b6.ns_jft_in1k.\n",
            "  model = create_fn(\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/173M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c43add60463d448b997bd979ab7b889f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3312636516.py:138: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/tmp/ipython-input-3312636516.py:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1/20] Train Acc: 0.7963 | Val Acc: 0.9744\n",
            "✅ Best model saved\n",
            "[Epoch 2/20] Train Acc: 0.9365 | Val Acc: 0.9744\n",
            "[Epoch 3/20] Train Acc: 0.9825 | Val Acc: 0.9615\n",
            "[Epoch 4/20] Train Acc: 0.9926 | Val Acc: 0.9744\n",
            "[Epoch 5/20] Train Acc: 0.9963 | Val Acc: 0.9744\n",
            "[Epoch 6/20] Train Acc: 0.9968 | Val Acc: 0.9615\n",
            "[Epoch 7/20] Train Acc: 0.9968 | Val Acc: 0.9872\n",
            "✅ Best model saved\n",
            "[Epoch 8/20] Train Acc: 0.9979 | Val Acc: 0.9872\n",
            "[Epoch 9/20] Train Acc: 0.9968 | Val Acc: 0.9872\n",
            "[Epoch 10/20] Train Acc: 0.9979 | Val Acc: 0.9744\n",
            "[Epoch 11/20] Train Acc: 0.9963 | Val Acc: 0.9487\n",
            "[Epoch 12/20] Train Acc: 0.9984 | Val Acc: 0.9487\n",
            "[Epoch 13/20] Train Acc: 0.9979 | Val Acc: 0.9615\n",
            "[Epoch 14/20] Train Acc: 0.9984 | Val Acc: 0.9615\n",
            "[Epoch 15/20] Train Acc: 0.9947 | Val Acc: 0.9615\n",
            "[Epoch 16/20] Train Acc: 0.9921 | Val Acc: 0.9744\n",
            "[Epoch 17/20] Train Acc: 0.9968 | Val Acc: 0.9744\n",
            "[Epoch 18/20] Train Acc: 0.9968 | Val Acc: 0.9872\n",
            "[Epoch 19/20] Train Acc: 0.9984 | Val Acc: 0.9615\n",
            "[Epoch 20/20] Train Acc: 0.9984 | Val Acc: 1.0000\n",
            "✅ Best model saved\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Blight       0.97      1.00      0.99        39\n",
            "     Healthy       0.90      1.00      0.95        18\n",
            "        Spot       1.00      0.85      0.92        20\n",
            "\n",
            "    accuracy                           0.96        77\n",
            "   macro avg       0.96      0.95      0.95        77\n",
            "weighted avg       0.96      0.96      0.96        77\n",
            "\n",
            "F1: 0.9512097040411498\n",
            "Recall: 0.9500000000000001\n",
            "Precision: 0.9583333333333334\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Model saved to Google Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the folder in drive with name of : models\n",
        "!mkdir -p /content/drive/MyDrive/Corn_efficientnet_B6_models\n",
        "\n",
        "# copying the model file to the drive folder with the mentioned name: models\n",
        "!cp /content/full_model.pth /content/drive/MyDrive/Corn_efficientnet_B6_models/\n",
        "\n",
        "\n",
        "save_folder = \"/content/drive/MyDrive/Corn_efficientnet_B6_models\"\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "\n",
        "torch.save(model, f\"{save_folder}/{MODEL_NAME}_full_model.pth\")\n",
        "torch.save(model.state_dict(), f\"{save_folder}/{MODEL_NAME}_weights_only.pth\")\n",
        "\n",
        "print(\"✅ ماډل په Google Drive کې ذخیره شو\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqcNM2Z0qDhC",
        "outputId": "df31ae31-8042-45b0-e857-83fc3a1b1a2b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/full_model.pth': No such file or directory\n",
            "✅ ماډل په Google Drive کې ذخیره شو\n"
          ]
        }
      ]
    }
  ]
}